{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat-<i>k</i> Gaussian <i>P(k)</i>\n",
    "\n",
    "Bobby Pascua and the HERA Validation Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Flat-k-Gaussian-P(k)\" data-toc-modified-id=\"Flat-k-Gaussian-P(k)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Flat-<i>k</i> Gaussian <i>P(k)</i></a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup-and-Metadata\" data-toc-modified-id=\"Setup-and-Metadata-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup and Metadata</a></span><ul class=\"toc-item\"><li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Abstract</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Software\" data-toc-modified-id=\"Software-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>Software</a></span></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1.1.6\"><span class=\"toc-item-num\">1.1.6&nbsp;&nbsp;</span>Data</a></span></li></ul></li><li><span><a href=\"#Data-Retrieval\" data-toc-modified-id=\"Data-Retrieval-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Data Retrieval</a></span><ul class=\"toc-item\"><li><span><a href=\"#Power-Spectrum-Retrieval\" data-toc-modified-id=\"Power-Spectrum-Retrieval-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Power Spectrum Retrieval</a></span></li><li><span><a href=\"#Power-Spectrum-Amplitude-Expectation\" data-toc-modified-id=\"Power-Spectrum-Amplitude-Expectation-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Power Spectrum Amplitude Expectation</a></span></li></ul></li><li><span><a href=\"#Data-Visualization\" data-toc-modified-id=\"Data-Visualization-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Data Visualization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensemble-Averaged-Power-Spectrum\" data-toc-modified-id=\"Ensemble-Averaged-Power-Spectrum-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Ensemble-Averaged Power Spectrum</a></span></li><li><span><a href=\"#Histograms\" data-toc-modified-id=\"Histograms-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Histograms</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook validates the `hera_pspec.pspecdata` pipeline's ability to recover a flat-<i>k</i> Gaussian power spectrum from an ensemble of noiseless simulations. We extract the power spectrum estimate from each simulation using the `hera_pspec.pspecdata` pipeline and perform an ensemble average on the resulting spectra. We find agreement between the measured and predicted power spectrum amplitude at the 0.15% level. Additionally, we histogram the measured powers from the full ensemble and find that the distribution is consistent with an exponential distribution, with the scale parameter given by the expected power spectrum amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hera_pspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aa2984836e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhera_pspec\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyuvdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUVData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyuvdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hera_pspec'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "from IPython.utils import io\n",
    "from datetime import datetime\n",
    "\n",
    "import hera_pspec as hp\n",
    "from pyuvdata import UVData\n",
    "import pyuvdata\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n",
       "MathJax.Hub.Queue(\n",
       "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
       "  [\"PreProcess\", MathJax.Hub],\n",
       "  [\"Reprocess\", MathJax.Hub]\n",
       ");\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "str(datetime.now())": "<p><strong>NameError</strong>: name &#39;datetime&#39; is not defined</p>\n"
    }
   },
   "source": [
    "Last executed: {{str(datetime.now())}}\n",
    "\n",
    "- **Major Step Description:** Simulate sky-locked, white-spectrum Gaussian field and estimate power spectrum with `hera_pspec.pspecdata`\n",
    "- **Minor Variation Description:** Generate flat-k, sky-locked Gaussian field and estimate power spectrum from an ensemble average.\n",
    "- **Pipelines Tested:** `hera_pspec.pspecdata`\n",
    "- **Criteria**:\n",
    "  1. Ensemble averaged power spectrum agrees with analytic prediction to within the predicted mean standard error.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this validation test, in reference to the outlined criteria, are\n",
    "1. Test passed; ensemble averaged power spectrum estimate agrees with analytic expectation to (0.16$\\pm$0.01)%\n",
    "\n",
    "The ensemble of power spectrum estimates was histogrammed and the result nearly perfectly follows an exponential distribution with scale parameter set by the expected power spectrum amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "hp.version.git_hash": "<p><strong>NameError</strong>: name &#39;hp&#39; is not defined</p>\n",
     "np.version.version": "<p><strong>NameError</strong>: name &#39;np&#39; is not defined</p>\n",
     "pyuvdata.version.git_hash": "<p><strong>NameError</strong>: name &#39;pyuvdata&#39; is not defined</p>\n"
    }
   },
   "source": [
    "HERA software used in this validation test, with associate git commit hash:\n",
    "\n",
    "* ``hera_pspec``: ``{{hp.version.git_hash}}``\n",
    "* ``pyuvdata``: ``{{pyuvdata.version.git_hash}}``\n",
    "\n",
    "Versions of other software used in this validation test:\n",
    "\n",
    "* ``numpy``: ``v{{np.version.version}}``\n",
    "* ``matplotlib``: ``v{{plt.matplotlib.__version__}}``\n",
    "* ``multiprocessing``: ``v{{mp.__version__}}``\n",
    "* ``re``: ``v{{re.__version__}}``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following paths reflect the exact locations of all data used in this test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = \"/lustre/aoc/projects/hera/alanman/eor_sky_sim/\"\n",
    "path1 = \"/lustre/aoc/projects/hera/Validation/test-0.1.0/Spectra/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Spectrum Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section offers two methods of retrieving the ensemble of power spectra: the first is by loading in the pre-processed power spectra, while the second involves obtaining the power spectra from the visibility data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to make a glob of the pre-processed files, make glob of sim files if not\n",
    "try:\n",
    "    dfiles = sorted(glob.glob('{}eor*.npz'.format(path1)))\n",
    "    data = np.load(dfiles[0])['arr_0']\n",
    "    prepro = True\n",
    "except:\n",
    "    dfiles = sorted(glob.glob('{}*24.*.uvh5'.format(path0)))\n",
    "    prepro = False\n",
    "\n",
    "# either way, we want to make a histogram, so let's define the bin edges\n",
    "bins = np.linspace(0, 1e7, 49)\n",
    "\n",
    "# if pre-processed files can't be found, then we need to process the simulation files\n",
    "if not prepro:\n",
    "    # if we can't find the pre-processed files, then they must not be on the cluster\n",
    "    # so let's just process all the files and save them\n",
    "    \n",
    "    # define a function that accepts an input uvh5 file, calculates the power spectrum,\n",
    "    # and saves the result in a PSpecContainer object\n",
    "    def calc_pspec(infile):\n",
    "        # use regular expressions to get simulation number\n",
    "        p1 = re.compile('\\d+.uvh5')\n",
    "        substr = p1.findall(infile)[0]\n",
    "        p2 = re.compile('\\d+')\n",
    "        fnum = p2.findall(substr)[0]\n",
    "        # make name for PSpecContainer save file\n",
    "        outfile = '{}eorsky_spec{}'.format(path1,fnum)\n",
    "        \n",
    "        # initialize UVData object and load infile\n",
    "        uvd = UVData()\n",
    "        # read data file, but suppress message about eorsky not being a known telescope\n",
    "        with io.capture_output() as captured:\n",
    "            uvd.read_uvh5(infile)\n",
    "        \n",
    "        # define the cosmology\n",
    "        cosmo = hp.conversions.Cosmo_Conversions()\n",
    "        \n",
    "        # get parameters for making a Gaussian beam\n",
    "        bm_fwhm = np.radians(uvd.extra_keywords[u'bm_fwhm'])\n",
    "        freqs = np.unique(uvd.freq_array)\n",
    "        \n",
    "        # make the beam\n",
    "        beam = hp.PSpecBeamGauss(bm_fwhm, freqs, cosmo=cosmo)\n",
    "        \n",
    "        # make blpairs using only autopairs\n",
    "        bls = uvd.get_antpairs()\n",
    "        blpairs = zip(bls, bls)\n",
    "            \n",
    "        # define tapers to be used\n",
    "        tapers = ['blackman-harris', 'none']\n",
    "        \n",
    "        # make sure output is in temperature units\n",
    "        Jy2mK = uvd.vis_units.upper()=='JY'\n",
    "        \n",
    "        # calculate the spectra with pspec_run for each taper\n",
    "        for taper in tapers:\n",
    "            # update outfile name\n",
    "            outfile = '{}_{}.psc'.format(outfile, taper)\n",
    "            \n",
    "            # capture the output from when Jy2mK is asked to act on a dset already set\n",
    "            # to mK units\n",
    "            with io.capture_output() as captured:\n",
    "                # get power spectrum\n",
    "                psc, ds = hp.pspecdata.pspec_run([uvd,uvd], outfile, blpairs=blpairs,\n",
    "                                                 taper=taper, beam=beam, cosmo=cosmo,\n",
    "                                                 Jy2mK=Jy2mK, verbose=False)\n",
    "        return 0\n",
    "    \n",
    "    # now process the files in parallel\n",
    "    if __name__=='__main__':\n",
    "        # get the user name to retrieve number of processors requested for job\n",
    "        user = !whoami\n",
    "        user = user[0]\n",
    "        \n",
    "        # assume everyone follows the guidelines for using jupyter notebooks\n",
    "        # and assume that an interactive job using multiple processors is run\n",
    "        # using the job scheduler\n",
    "        try:\n",
    "            jn_pbs_path = '/users/{}/jupyter_notebook.pbs'.format(user)\n",
    "        except:\n",
    "            print('Please set up a jupyter_notebook.pbs script in your personal directory.')\n",
    "            sys.exit()\n",
    "        with open(jn_pbs_path) as f:\n",
    "            # read the contents of the .pbs script\n",
    "            text = f.read()\n",
    "            \n",
    "            # use regular expressions to find the number of processors requested\n",
    "            p1 = re.compile('nodes=\\d+')\n",
    "            p2 = re.compile('ppn=\\d+')\n",
    "            p3 = re.compile('\\d+')\n",
    "            \n",
    "            nodes = int(p3.findall(p1.findall(text)[0])[0])\n",
    "            ppn = int(p3.findall(p2.findall(text)[0])[0])\n",
    "            \n",
    "            Nprocs = nodes * ppn\n",
    "            \n",
    "            # check that the interactive job has enough memory requested, since\n",
    "            # each instance of an opened uvh5 file via UVData requires approx\n",
    "            # 2 GB of memory\n",
    "            p1 = re.compile('vmem=\\d+G')\n",
    "            mem = int(p3.findall(p1.findall(text)[0])[0])\n",
    "            # require that there be at least 2 GB of memory available when all\n",
    "            # workers are doing something\n",
    "            if mem - (Nprocs - nodes)*2 < 2:\n",
    "                err_msg = 'Update your jupyter_notebook.pbs file to request at least' \\\n",
    "                          '{} GB of memory.'.format(2*(Nprocs-nodes+1))\n",
    "                print(err_msg)\n",
    "                sys.exit()\n",
    "            # put a message here letting the user know approximately how long\n",
    "            # it will take to process all the files\n",
    "        \n",
    "        # start pool of workers, leaving one free processor per node\n",
    "        pool = mp.Pool(max(1,Nprocs-nodes))\n",
    "        # process files in parallel\n",
    "        pool.map(calc_pspec, dfiles)\n",
    "        # close the pool\n",
    "        pool.close()\n",
    "        \n",
    "    # now that the files have been processed, let's retrieve the ensemble averaged pspec\n",
    "    \n",
    "    # first, define some things for some clarity on what's happening\n",
    "    # first, load in one of the simulation files\n",
    "    uvd = UVData()\n",
    "    uvd.read_uvh5(dfiles[np.random.randint(low=0,high=len(dfiles))])\n",
    "    \n",
    "    # next, define the tapers used in this analysis\n",
    "    tapers = ['blackman-harris', 'none']\n",
    "    \n",
    "    # now get the baseline pairs; these are (0,11), (0,12), (11,12)\n",
    "    bls = uvd.get_antpairs()\n",
    "    blpairs = zip(bls,bls)\n",
    "    \n",
    "    # get the size of the time array\n",
    "    Ntimes = len(np.unique(uvd.time_array))\n",
    "    \n",
    "    # get the size of the frequency array\n",
    "    Nfreqs = len(np.unique(uvd.freq_array))\n",
    "    \n",
    "    # initialize an array to hold the averaged spectrum\n",
    "    avg_spec = np.zeros( (len(tapers), len(blpairs), Ntimes, Nfreqs), dtype='complex128' )\n",
    "    \n",
    "    # also initialize an array for the histograms\n",
    "    hist = np.zeros( (len(tapers), len(blpairs), len(bins)-1), dtype='float64' )\n",
    "    \n",
    "    # loop over tapers\n",
    "    for i, taper in enumerate(tapers):\n",
    "        # make glob of data files\n",
    "        specfiles = sorted(glob.glob('{}*{}.psc'.format(path1, taper)))\n",
    "        \n",
    "        # now loop over files\n",
    "        for f in specfiles:\n",
    "            # load PSpecContainer object\n",
    "            psc = hp.container.PSpecContainer(f)\n",
    "            \n",
    "            # get UVPSpec object from pspec container\n",
    "            uvp = psc.get_pspec(psc.groups()[0])[0]\n",
    "            \n",
    "            # loop over baseline pairs\n",
    "            for j, blp in enumerate(blpairs):\n",
    "                # make key to get pspec\n",
    "                # we used the full spectral range, so spw = 0\n",
    "                # all of the data has polarization pI\n",
    "                key = (0, blp, 'pI')\n",
    "                \n",
    "                # retrieve the power spectrum\n",
    "                pspec = uvp.get_data(key)\n",
    "                \n",
    "                # add it to the ensemble average array\n",
    "                avg_spec[i,j] += pspec\n",
    "                \n",
    "                # update the histogram\n",
    "                hist[i,j] += np.histogram(pspec.real, bins=bins)[0]\n",
    "                \n",
    "                # normalize the histogram\n",
    "                hist[i,j] /= hist[i,j].sum()\n",
    "                            \n",
    "    # divide out by the number of files for the ensemble average\n",
    "    avg_spec /= len(dfiles)\n",
    "    \n",
    "else:\n",
    "    # get the ensemble average and fill out the histogram\n",
    "    \n",
    "    # first, make an array of zeros for the ensemble average\n",
    "    avg_spec = np.zeros(data.shape, dtype='complex128')\n",
    "    \n",
    "    # since we were able to load in the pre-processed files, let's make\n",
    "    # histograms for spectra computed with and without a taper\n",
    "    hist = np.zeros( (2, 3,len(bins)-1), dtype='float64')\n",
    "    \n",
    "    # we'll need to loop over data files\n",
    "    for f in dfiles:\n",
    "        # load in the data\n",
    "        data = np.load(f)['arr_0']\n",
    "        \n",
    "        # add it to the average spectrum, to be divided by the number of realizations\n",
    "        # later on in the script\n",
    "        avg_spec += data\n",
    "        \n",
    "        # update the histograms, but do this on a per-baseline basis\n",
    "        # we need to take the abs of the data first for histogramming\n",
    "        data = np.abs(data)\n",
    "        # from the README, axis-1 corresponds to baselines\n",
    "        for j in range(data.shape[1]):\n",
    "            # axis-0 corresponds to taper choice\n",
    "            # data[0] -> bh-taper\n",
    "            # data[1] -> no taper\n",
    "            hist[0,j] += np.histogram(data[1,j], bins=bins)[0]\n",
    "            hist[1,j] += np.histogram(data[0,j], bins=bins)[0]\n",
    "            \n",
    "    # we're done with our loops, so now divide the average spectrum array by the \n",
    "    # number of realizations\n",
    "    avg_spec /= len(dfiles)\n",
    "    \n",
    "    # let's normalize the histograms while we're at it\n",
    "    for j in range(hist.shape[1]):\n",
    "        hist[0,j] /= hist[0,j].sum()\n",
    "        hist[1,j] /= hist[1,j].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Spectrum Amplitude Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we determine the expected amplitude of the power spectrum. The expected amplitude is given by $P_0 = \\sigma^2\\Delta\\nu\\Delta\\Omega X^2Y$, where $\\sigma^2$ is the variance of the sky-locked, spectrally-flat Gaussian distribution of 21-cm brightness temperature fluctuations; $\\Delta\\nu$ is the size of a frequency channel; $\\Delta\\Omega$ is the size of a pixel in the HEALPix map used for the simulation, given by $\\Delta\\Omega = 4\\pi/(12N_{side}^2)$; $X$ and $Y$ are cosmological scalars, used in the usual sense, evaluated at the redshift of the 21-cm line at band-center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a glob of simulation files and choose one at random\n",
    "dfile = glob.glob('{}*24*.uvh5'.format(path0))[0]\n",
    "\n",
    "# instantiate a UVData object and read the data file\n",
    "uvd = UVData()\n",
    "uvd.read_uvh5(dfile)\n",
    "\n",
    "# get the parameters needed to compute the expected amplitude of the power spectrum\n",
    "nside = uvd.extra_keywords[u'nside']\n",
    "dOmega = 4*np.pi/(12*nside**2)                 # sr\n",
    "skysig = uvd.extra_keywords[u'skysig'] * 1e3   # mK\n",
    "df = np.diff(np.unique(uvd.freq_array)).mean() # Hz\n",
    "f0 = 1420405751.767         # HI rest-frequency, Hz\n",
    "z = f0/np.median(np.unique(uvd.freq_array)) - 1 # redshift of HI line at band-center\n",
    "X2Y = hp.conversions.Cosmo_Conversions().X2Y(z) # (h^-1 Mpc)^3 sr^-1 Hz^-1\n",
    "\n",
    "# calculate expected power spectrum amplitude\n",
    "P0 = skysig**2*df*dOmega*X2Y                    # mK^2 h^-3 Mpc^3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we visualize the data collected in the previous section. We compare the ensemble-averaged power spectra to the expected power spectrum amplitude on a per-baseline basis, and we also examine the result averaged over baselines. We conclude the section by displaying the histograms calculated above, again on a per-baseline basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble-Averaged Power Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference in the beam-squared integral (between the simulation and the\n",
    "# analytic result for a Gaussian beam), and get the delays for the power spectrum\n",
    "\n",
    "# define the cosmology\n",
    "cosmo = hp.conversions.Cosmo_Conversions()\n",
    "\n",
    "# get the beam fwhm\n",
    "bm_fwhm = np.radians(uvd.extra_keywords[u'bm_fwhm'])\n",
    "\n",
    "# make the beam object\n",
    "uvb = hp.PSpecBeamGauss(fwhm=bm_fwhm, beam_freqs=np.unique(uvd.freq_array), cosmo=cosmo)\n",
    "\n",
    "# get the beam-squared integral from the extra keywords and calculate it with hera_pspec\n",
    "bsq_int = uvd.extra_keywords[u'bsq_int']\n",
    "bsq_int_hp = uvb.power_beam_sq_int(pol='pI').mean()\n",
    "\n",
    "# get the difference in the beam-squared integral\n",
    "# hera_pspec uses the analytic result, so we'll take that as the reference\n",
    "# for the correct value\n",
    "bsq_int_diff = bsq_int_hp - bsq_int\n",
    "bsq_int_diff_pct = 100*bsq_int_diff/bsq_int_hp\n",
    "\n",
    "# use hera_pspec.utils.get_delays to get the delays\n",
    "dlys = hp.utils.get_delays(np.unique(uvd.freq_array))\n",
    "\n",
    "# make a list of baselines\n",
    "bls = uvd.get_antpairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the results over time (axis-2) and plot the resulting delay spectrum for\n",
    "# each baseline, as well as the baseline-averaged result. for bonus points, include\n",
    "# a smaller figure with each plot showing the residual?\n",
    "time_avg_spec = avg_spec.mean(axis=2)\n",
    "bl_avg_spec = time_avg_spec.mean(axis=1)\n",
    "\n",
    "colors = ['teal', 'magenta', 'gold']\n",
    "tapers = ['Blackman-Harris', 'No']\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "axes = fig.subplots(2,1)\n",
    "for j, taper in enumerate(tapers):\n",
    "    # label axes\n",
    "    axes[j].set_xlabel('Delay [ns]', fontsize=12)\n",
    "    axes[j].set_ylabel(r'Power [mK$^2$ $h^{-3}$ Mpc$^3$]', fontsize=12)\n",
    "    axes[j].set_title('Ensemble Averaged Power Spectrum Estimate Using {} Taper'.format(taper), fontsize=12)\n",
    "\n",
    "    # plot spectra for each baseline\n",
    "    for k, bl in enumerate(bls):\n",
    "        axes[j].plot(dlys, time_avg_spec[j,k], color=colors[k], alpha=0.7, label=bl)\n",
    "    \n",
    "    # plot baseline-averaged spectrum\n",
    "    axes[j].plot(dlys, bl_avg_spec[j], color='k', alpha=0.7, label='Baseline Average')\n",
    "    \n",
    "    # plot expected amplitude\n",
    "    axes[j].axhline(P0, ls='--', color='k', alpha=0.8, label='Expected Value')\n",
    "    \n",
    "    # make a legend\n",
    "    axes[j].legend(ncol=2)\n",
    "\n",
    "# show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1 |** Time-averaged delay spectra of the ensemble-averaged power spectrum, plotted by baseline and compared to the baseline-average. The horizontal dashed line shows the expected power spectrum amplitude. The top plot shows the results calculated using a Blackman-Harris taper, whereas the bottom plot shows results calculated using no taper. Visually, the ensemble-averaged power spectrum looks to give a very good estimate of the actual power spectrum simulated, regardless of the taper used; see the output of the following cell for a breakdown of the discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the discrepancy in the results numerically\n",
    "\n",
    "# calculate estimated power spectrum amplitudes\n",
    "avg_spec_amps = time_avg_spec.mean(axis=-1)\n",
    "\n",
    "# loop over tapers\n",
    "for j, taper in enumerate(tapers):\n",
    "    # loop over baselines\n",
    "    for k, bl in enumerate(bls):\n",
    "        disc = 100*(P0 - avg_spec_amps[j,k])/P0\n",
    "        print('\\nDiscrepancy for baseline {} with {} taper: {:4.3f}%'.format(bl, taper, disc))\n",
    "    \n",
    "    # show discrepancy for baseline-averaged results\n",
    "    disc = 100*(P0 - avg_spec_amps[j].mean())/P0\n",
    "    print('\\nDiscrepancy for baseline-average with {} taper: {:4.3f}%'.format(taper, disc))\n",
    "    \n",
    "# for reference, show discrepancy in beam-squared integral\n",
    "print('\\nDiscrepancy in beam-squared integral: {:4.3f}%'.format(bsq_int_diff_pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate an exponential distribution using the bins from earlier and the power\n",
    "# spectrum expected amplitude. normalize it by using .sum() on the array. plot the\n",
    "# histograms on top of the exponential distribution.\n",
    "powers = 0.5*(bins[1:] + bins[:-1])\n",
    "exp_dist = np.exp(-powers/P0)\n",
    "normed_exp = exp_dist/exp_dist.sum()\n",
    "\n",
    "# make plots\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "axes = fig.subplots(3,2)\n",
    "for j, bl in enumerate(bls):\n",
    "    for k, taper in enumerate(tapers):\n",
    "        # label axes\n",
    "        axes[j,k].set_xlabel(r'Power [mK$^2$ $h^{-3}$ Mpc$^3$]', fontsize=12)\n",
    "        axes[j,k].set_ylabel(r'$N/N_\\mathrm{tot}$', fontsize=12)\n",
    "        axes[j,k].set_title('Baseline: {}; Taper: {}'.format(bl, taper))\n",
    "        \n",
    "        # plot exponential distribution first\n",
    "        axes[j,k].plot(powers, normed_exp, color='magenta', alpha=0.6, label='Expected Distribution')\n",
    "        \n",
    "        # plot measured distribution\n",
    "        axes[j,k].scatter(powers, hist[k,j], color='k', marker='o', label='Measured Distribution')\n",
    "        \n",
    "        # add a legend\n",
    "        axes[j,k].legend(loc='upper right')\n",
    "        \n",
    "# show the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2 |** Plots detailing the distribution of estimated powers. Each histogram was computed over the entire ensemble of power spectrum estimates, on a per-baseline and per-taper basis. The magenta line overplotted is an exponential distribution with scale parameter given by the expected power spectrum amplitude, normalized so that the sum of the distribution is unity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
