{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaginary Power from Time-Offset Visibilities\n",
    "\n",
    "Bobby Pascua and the HERA Validation Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how a power spectrum estimate may have a nonvanishing imaginary component when derived from time-offset visibility measurements of an uncorrelated, Gaussian sky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "from IPython.utils import io\n",
    "from datetime import datetime\n",
    "\n",
    "import aipy\n",
    "import healpy as hpy\n",
    "import hera_pspec as hp\n",
    "from pyuvdata import UVData\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n",
       "MathJax.Hub.Queue(\n",
       "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
       "  [\"PreProcess\", MathJax.Hub],\n",
       "  [\"Reprocess\", MathJax.Hub]\n",
       ");"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last executed: {str(datetime.now())}\n",
    "\n",
    "- **Major Step Description:** Simulate sky-locked, white-spectrum Gaussian field and estimate power spectrum with `hera_pspec.pspecdata`.\n",
    "- **Minor Variation Description:** Correctly predict the average imaginary power introduced to the power spectrum estimate when using time-offset visibilities to estimate $P(k)$.\n",
    "- **Pipelines Tested:** `hera_pspec.pspecdata`?\n",
    "- **Criteria**:\n",
    "  1. Imaginary component of ensemble average computed with `hera_pspec.pspecdata` agrees with semi-analytic expectation to ??? %\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of this validation test, in reference to the outlined criteria, are\n",
    "1. {Test results for criteria 1}\n",
    "2. {Test results for criteria 2...}\n",
    "\n",
    "{Brief notes on anything else interesting that was noted during testing}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERA software used in this validation test, with associate git commit hash:\n",
    "\n",
    "* ``pyuvdata``: ``d1829efacb60da384f64a8f25a280441bfa9d68a``\n",
    "* ``hera_pspec``: ``aca65860d5624356607874d82e3ad1290e6d09fa``\n",
    "\n",
    "Versions of other software used in this validation test:\n",
    "\n",
    "* ``aipy``: ``v3.0.0rc2``\n",
    "* ``healpy``: ``v1.12.9``\n",
    "* ``multiprocessing``: ``v0.70a1`` (assumed; not documented in Python 3 implementation)\n",
    "* ``matplotlib``: ``v3.1.0``\n",
    "* ``numpy``: ``v1.16.4``\n",
    "* ``re``: ``v2.2.1``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following paths reflect the exact locations of all data used in this test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = \"/lustre/aoc/projects/hera/alanman/eor_sky_sim/\"\n",
    "path1 = \"/lustre/aoc/projects/hera/Validation/test-0.1.0/Spectra/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectrum Retrieval from Visibility Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we show how the power spectra were obtained for this variation of step 0.1. The details are mostly the same as in step-0.1.0, with the slight modification of splitting the visibility data for each simulation into two sets of visibility data: one set corresponds to all the even-indexed time values, whereas the other corresponds to all the odd-indexed time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to make a glob of the pre-processed files, make glob of sim files if not\n",
    "try:\n",
    "    dfiles = sorted(glob.glob('{}eor*.npz'.format(path1)))\n",
    "    data = np.load(dfiles[0])['arr_1']\n",
    "    # XXX do we want to look at the distribution of imaginary powers? can we predict what it will be?\n",
    "    print('Preprocessed files found. Now histogramming powers and computing ensemble averaged spectrum.')\n",
    "    prepro = True\n",
    "except:\n",
    "    dfiles = sorted(glob.glob('{}*24.*.uvh5'.format(path0)))\n",
    "    print('Preprocessed files not found. Now beginning power spectrum extraction.')\n",
    "    print('WARNING: This process may take up to 30 hours. To speed up the process, ensure \\\n",
    "           \\nthat your interactive job has requested multiple processors per node and sufficient \\\n",
    "           \\nmemory. We recommend at least 5 processors and 64 GB memory.')\n",
    "    prepro = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either way, we want to make a histogram, so let's define the bin edges\n",
    "bins = np.linspace(0, 1e5, 49)\n",
    "\n",
    "# if pre-processed files can't be found, then we need to process the simulation files\n",
    "if not prepro:\n",
    "    # if we can't find the pre-processed files, then they must not be on the cluster\n",
    "    # so let's just process all the files and save them\n",
    "    \n",
    "    # define a function that accepts an input uvh5 file, calculates the power spectrum,\n",
    "    # and saves the result in a PSpecContainer object\n",
    "    def calc_pspec(infile):\n",
    "        # use regular expressions to get simulation number\n",
    "        p1 = re.compile('\\d+.uvh5')\n",
    "        substr = p1.findall(infile)[0]\n",
    "        p2 = re.compile('\\d+')\n",
    "        fnum = p2.findall(substr)[0]\n",
    "        # make name for PSpecContainer save file\n",
    "        outfile = '{}eorsky_offset_spec{}'.format(path1,fnum)\n",
    "        \n",
    "        # initialize UVData object and load infile\n",
    "        uvd = UVData()\n",
    "        # read data file, but suppress message about eorsky not being a known telescope\n",
    "        with io.capture_output() as captured:\n",
    "            uvd.read_uvh5(infile)\n",
    "        \n",
    "        # define the cosmology\n",
    "        cosmo = hp.conversions.Cosmo_Conversions()\n",
    "        \n",
    "        # get parameters for making a Gaussian beam\n",
    "        bm_fwhm = np.radians(uvd.extra_keywords[u'bm_fwhm'])\n",
    "        freqs = np.unique(uvd.freq_array)\n",
    "        \n",
    "        # make the beam\n",
    "        beam = hp.PSpecBeamGauss(bm_fwhm, freqs, cosmo=cosmo)\n",
    "        \n",
    "        # make blpairs using only autopairs\n",
    "        bls = uvd.get_antpairs()\n",
    "        blpairs = zip(bls, bls)\n",
    "            \n",
    "        # define tapers to be used\n",
    "        tapers = ['blackman-harris', 'none']\n",
    "        \n",
    "        # make sure output is in temperature units\n",
    "        Jy2mK = uvd.vis_units.upper()=='JY'\n",
    "        \n",
    "        # split visibilities according to even/odd time indices\n",
    "        times = np.unique(np.array(uvd.time_array))\n",
    "        uvd1 = uvd.select(times=times[:-1:2], inplace=False)\n",
    "        uvd2 = uvd.select(times=times[1::2], inplace=False)\n",
    "        \n",
    "        # calculate the spectra with pspec_run for each taper\n",
    "        for taper in tapers:\n",
    "            # update outfile name\n",
    "            outfile = '{}_{}.psc'.format(outfile, taper)\n",
    "            \n",
    "            # capture the output from when Jy2mK is asked to act on a dset already set\n",
    "            # to mK units\n",
    "            with io.capture_output() as captured:\n",
    "                # get power spectrum\n",
    "                psc, ds = hp.pspecdata.pspec_run([uvd1,uvd2], outfile, blpairs=blpairs,\n",
    "                                                 taper=taper, beam=beam, cosmo=cosmo,\n",
    "                                                 Jy2mK=Jy2mK, verbose=False)\n",
    "        return 0\n",
    "    \n",
    "    # now process the files in parallel\n",
    "    if __name__=='__main__':\n",
    "        # get the user name to retrieve number of processors requested for job\n",
    "        user = !whoami\n",
    "        user = user[0]\n",
    "        \n",
    "        # assume everyone follows the guidelines for using jupyter notebooks\n",
    "        # and assume that an interactive job using multiple processors is run\n",
    "        # using the job scheduler\n",
    "        try:\n",
    "            jn_pbs_path = '/users/{}/jupyter_notebook.pbs'.format(user)\n",
    "        except:\n",
    "            print('Please set up a jupyter_notebook.pbs script in your personal directory.')\n",
    "            sys.exit()\n",
    "        with open(jn_pbs_path) as f:\n",
    "            # read the contents of the .pbs script\n",
    "            text = f.read()\n",
    "            \n",
    "            # use regular expressions to find the number of processors requested\n",
    "            p1 = re.compile('nodes=\\d+')\n",
    "            p2 = re.compile('ppn=\\d+')\n",
    "            p3 = re.compile('\\d+')\n",
    "            \n",
    "            nodes = int(p3.findall(p1.findall(text)[0])[0])\n",
    "            ppn = int(p3.findall(p2.findall(text)[0])[0])\n",
    "            \n",
    "            # check that the interactive job has enough memory requested, since\n",
    "            # each instance of an opened uvh5 file via UVData requires approx\n",
    "            # 2 GB of memory\n",
    "            p1 = re.compile('vmem=\\d+G')\n",
    "            mem = int(p3.findall(p1.findall(text)[0])[0])\n",
    "\n",
    "            \n",
    "        # choose number of processors such that there won't be a MemoryError,\n",
    "        # but also such that at least one processor is used\n",
    "        Nprocs = max(1,min(mem/4 - nodes, nodes*(ppn - 1)))\n",
    "        # note that there are times in the pspec pipeline where the data is copied\n",
    "        # before it is discarded; this can cause memory spikes up to Nprocs * 4 GB\n",
    "        # when the pspec pipeline is run in parallel over Nprocs processors\n",
    "\n",
    "        # start pool of workers\n",
    "        pool = mp.Pool(Nprocs)\n",
    "        # process files in parallel\n",
    "        pool.map(calc_pspec, dfiles)\n",
    "        # close the pool\n",
    "        pool.close()\n",
    "        \n",
    "    # now that the files have been processed, let's retrieve the ensemble averaged pspec\n",
    "    \n",
    "    # first, define some things for some clarity on what's happening\n",
    "    # first, load in one of the simulation files\n",
    "    uvd = UVData()\n",
    "    uvd.read_uvh5(dfiles[np.random.randint(low=0,high=len(dfiles))])\n",
    "    \n",
    "    # next, define the tapers used in this analysis\n",
    "    tapers = ['blackman-harris', 'none']\n",
    "    \n",
    "    # now get the baseline pairs; these are (0,11), (0,12), (11,12)\n",
    "    bls = uvd.get_antpairs()\n",
    "    blpairs = zip(bls,bls)\n",
    "    \n",
    "    # get the size of the time array\n",
    "    Ntimes = len(np.unique(uvd.time_array))/2 # visibilities were split in half by time\n",
    "    \n",
    "    # get the size of the frequency array\n",
    "    Nfreqs = len(np.unique(uvd.freq_array))\n",
    "    \n",
    "    # initialize an array to hold the averaged spectrum\n",
    "    avg_spec = np.zeros( (len(tapers), len(blpairs), Ntimes, Nfreqs), dtype='complex128' )\n",
    "    \n",
    "    # also initialize an array for the histograms\n",
    "    hist = np.zeros( (len(tapers), len(blpairs), len(bins)-1), dtype='float64' )\n",
    "    \n",
    "    # loop over tapers\n",
    "    for i, taper in enumerate(tapers):\n",
    "        # make glob of data files\n",
    "        specfiles = sorted(glob.glob('{}*offset*{}.psc'.format(path1, taper)))\n",
    "        \n",
    "        # now loop over files\n",
    "        for specfile in specfiles:\n",
    "            # load PSpecContainer object\n",
    "            psc = hp.container.PSpecContainer(specfile)\n",
    "            \n",
    "            # get UVPSpec object from pspec container\n",
    "            uvp = psc.get_pspec(psc.groups()[0])[0]\n",
    "            \n",
    "            # loop over baseline pairs\n",
    "            for j, blp in enumerate(blpairs):\n",
    "                # make key to get pspec\n",
    "                # we used the full spectral range, so spw = 0\n",
    "                # all of the data has polarization pI\n",
    "                key = (0, blp, 'pI')\n",
    "                \n",
    "                # retrieve the power spectrum\n",
    "                pspec = uvp.get_data(key)\n",
    "                \n",
    "                # add it to the ensemble average array\n",
    "                avg_spec[i,j] += pspec\n",
    "                \n",
    "                # update the histogram\n",
    "                hist[i,j] += np.histogram(pspec.real, bins=bins)[0]\n",
    "                \n",
    "                # normalize the histogram\n",
    "                hist[i,j] /= hist[i,j].sum()\n",
    "                            \n",
    "    # divide out by the number of files for the ensemble average\n",
    "    avg_spec /= len(dfiles)\n",
    "    \n",
    "else:\n",
    "    # get the ensemble average and fill out the histogram\n",
    "    \n",
    "    # first, make an array of zeros for the ensemble average\n",
    "    avg_spec = np.zeros(data.shape, dtype='complex128')\n",
    "    \n",
    "    # since we were able to load in the pre-processed files, let's make\n",
    "    # histograms for spectra computed with and without a taper\n",
    "    hist = np.zeros( (2, 3,len(bins)-1), dtype='float64')\n",
    "    \n",
    "    # we'll need to loop over data files\n",
    "    for dfile in dfiles:\n",
    "        # load in the data\n",
    "        data = np.load(dfile)['arr_1']\n",
    "        \n",
    "        # add it to the average spectrum, to be divided by the number of realizations\n",
    "        # later on in the script\n",
    "        avg_spec += data\n",
    "        \n",
    "        # update the histograms, but do this on a per-baseline basis\n",
    "        # we need to take the abs of the data first for histogramming\n",
    "        data = np.abs(data)\n",
    "        # from the README, axis-1 corresponds to baselines\n",
    "        for j in range(data.shape[1]):\n",
    "            # axis-0 corresponds to taper choice\n",
    "            # data[0] -> bh-taper\n",
    "            # data[1] -> no taper\n",
    "            hist[0,j] += np.histogram(data[1,j], bins=bins)[0]\n",
    "            hist[1,j] += np.histogram(data[0,j], bins=bins)[0]\n",
    "            \n",
    "    # we're done with our loops, so now divide the average spectrum array by the \n",
    "    # number of realizations\n",
    "    avg_spec /= len(dfiles)\n",
    "    \n",
    "    # let's normalize the histograms while we're at it\n",
    "    for j in range(hist.shape[1]):\n",
    "        hist[0,j] /= hist[0,j].sum()\n",
    "        hist[1,j] /= hist[1,j].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Imaginary Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we outline the model used to predict the existence of imaginary power in the spectra computed in the previous section and present the computational methods used to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with our assumptions of the sky used to generate the visibility data used in the previous section. We assume that the signal is sky-locked and that the brightness temperature on the sky is normally distributed in frequency and angular position, and that the value of the brightness temperature in any voxel is uncorrelated with that in any other voxel. We additionally assume that the telescope beam is Gaussian, centered on zenith as determined by the (time-dependent) HERA position.  \n",
    "  \n",
    "In order to obtain a prediction for what we expect the `hera_pspec.pspecdata` pipeline to output, we begin with the power spectrum estimator given in Equation 4 of Parsons et al. (ApJ 788 (2), 106, 2014):  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{P}(\\mathbf{k}) = \\biggl(\\frac{\\lambda^2}{2k_b}\\biggr)^2\\frac{X^2Y}{\\Omega_\\mathrm{pp}B} \\Bigl\\langle\\tilde{V}_i(\\tau,t)\\tilde{V}^*_j(\\tau,t)\\Bigr\\rangle_{i<j}, \n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "where $\\lambda$ is the observing frequency, $X$ and $Y$ are cosmological scalars that convert angles and frequencies into comoving distances, $\\Omega_\\mathrm{pp}$ is the integral of the beam-power-squared over the sky, $B$ is the observing bandwidth, $\\langle\\cdots\\rangle_{i<j}$ denotes an average over redundant baselines, and $\\tilde{V}$ is the delay-transformed visibility. We use the usual definition of visibility in a sky-locked frame,  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "V(\\nu,t) = \\int \\mathrm{d}\\Omega A_\\nu(\\hat{\\mathbf{n}},t)I_\\nu(\\hat{\\mathbf{n}})\\mathrm{e}^{-i2\\pi\\nu\\mathbf{b}(t)\\cdot\\hat{\\mathbf{n}}/c},\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "where $A$ is the beam-power, $I$ is the intensity on the sky, and $\\mathbf{b}$ is the baseline making the visibility measurement. We define the brightness temperature $T_\\nu$ such that\n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "I_\\nu(\\hat{\\mathbf{n}}) = \\frac{2k_b}{\\lambda^2}T_\\nu(\\hat{\\mathbf{n}}).\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "The delay-transformed visibility is obtained by taking the Fourier transform of the visibility along the frequency-axis:\n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\tilde{V}(\\tau,t) =  \\frac{2k_b}{\\lambda^2}\\int \\mathrm{d}\\nu\\mathrm{d}\\Omega A_\\nu(\\hat{\\mathbf{n}},t)T_\\nu(\\hat{\\mathbf{n}})\\mathrm{e}^{-i2\\pi\\nu\\bigl(\\mathbf{b}(t)\\cdot\\hat{\\mathbf{n}}/c - \\tau\\bigr)}.\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "Using these definitions, we can rewrite the power spectrum estimator as  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{P}(\\mathbf{k}) = \\frac{X^2Y}{\\Omega_\\mathrm{pp}B}\\biggl\\langle\\int\\mathrm{d}\\nu'\\mathrm{d}\\nu\\mathrm{d}\\Omega'\\mathrm{d}\\Omega A_{\\nu'}(\\hat{\\mathbf{n}}',t)A_\\nu(\\hat{\\mathbf{n}},t)T_{\\nu'}(\\hat{\\mathbf{n}}')T_\\nu(\\hat{\\mathbf{n}})\\exp\\bigl(-i2\\pi(\\nu'-\\nu)\\tau\\bigr)\\exp\\bigl(-i2\\pi(\\nu'\\mathbf{b}_j\\cdot\\hat{\\mathbf{n}}'/c - \\nu\\mathbf{b}_i\\cdot\\hat{\\mathbf{n}}/c)\\bigr)\\biggr\\rangle.\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "(Complex conjugation has been left off of quantities assumed to be real-valued.) We now use the assumption that the temperature field is normally distributed and that the value it takes on in one voxel is independent from that of any other voxel, and take the average over redundant baselines to be an ensemble average, so that  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\bigl\\langle T_{\\nu'}(\\hat{\\mathbf{n}}')T_\\nu(\\hat{\\mathbf{n}})\\bigr\\rangle = \\sigma^2\\Delta\\nu\\Delta\\Omega\\delta_D(\\nu'-\\nu)\\delta_D(\\hat{\\mathbf{n}}'-\\hat{\\mathbf{n}}),\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "where $\\delta_D(\\cdots)$ indicates the Dirac delta function, $\\sigma^2$ is the variance of the temperature field, $\\Delta\\nu$ is the size of a frequency channel, and $\\Delta\\Omega$ is the solid angle subtended by a pixel (for our case, these must be the same value as those used for the simulation). From this, it follows that the power spectrum estimator simplifies to  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{P}(\\mathbf{k}) = \\sigma^2\\Delta\\nu\\Delta\\Omega\\frac{X^2Y}{\\Omega_\\mathrm{pp}B}\\int\\mathrm{d}\\nu\\mathrm{d}\\Omega |A_\\nu(\\hat{\\mathbf{n}},t)|^2\\exp\\bigl(-i2\\pi\\nu\\Delta \\mathbf{b}_{ij}(t)\\cdot\\hat{\\mathbf{n}}/c\\bigr),\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "where $\\Delta\\mathbf{b}_{ij} = \\mathbf{b}_j-\\mathbf{b}_i$. We can now evaluate the frequency integral over the bandwidth $\\nu\\in[\\nu_1,\\nu_2]$ where $\\nu_2 - \\nu_1 = B$ to get  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{P}(\\mathbf{k}) = \\sigma^2\\Delta\\nu\\Delta\\Omega\\frac{X^2Y}{\\Omega_\\mathrm{pp}B}\\int\\mathrm{d}\\Omega|A_\\nu(\\hat{\\mathbf{n}}, t)|^2\\frac{\\mathrm{e}^{-i2\\pi\\nu_2\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c} - \\mathrm{e}^{-i2\\pi\\nu_1\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c}}{-i2\\pi\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c}.\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "To put the above expression into a nicer form, let's define the band-center frequency $\\nu_0 = (\\nu_1 + \\nu_2)/2$, so that $\\nu_2 = \\nu_0 + B/2$ and $\\nu_1 = \\nu_0 - B/2$. We can then factor out $\\exp(-i2\\pi\\nu_0\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c)$ from the difference of exponentials and use Euler's identity, along with the identity $z - z^* = 2i\\mathrm{Im}(z)$ for any complex $z$, to rewrite the above equation as  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{P}(\\mathbf{k}) = \\sigma^2\\Delta\\nu\\Delta\\Omega\\frac{X^2Y}{\\Omega_\\mathrm{pp}B}\\int\\mathrm{d}\\Omega|A_\\nu(\\hat{\\mathbf{n}})|^2\\exp\\bigl(-i2\\pi\\nu_0\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c\\bigr)\\frac{\\sin(\\pi B\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c)}{\\pi\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c}.\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "We can pull the factor of $1/B$ under the integral and use the definition $\\mathrm{sinc}(x) \\equiv \\sin(x)/x$ to rewrite the above equation somewhat more compactly:  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\label{eq:pspec-expectation}\n",
    "\\hat{P}(\\mathbf{k}) = \\sigma^2\\Delta\\nu\\Delta\\Omega\\frac{X^2Y}{\\Omega_\\mathrm{pp}}\\int\\mathrm{d}\\Omega|A(\\hat{\\mathbf{n}}, t)|^2\\exp\\bigl(-i2\\pi\\nu_0\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c\\bigr)\\mathrm{sinc}\\bigl(\\pi B\\Delta\\mathbf{b}_{ij}\\cdot\\hat{\\mathbf{n}}/c\\bigr).\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "Notice that in the limit $\\Delta\\mathbf{b}_{ij} = 0$, the above equation reduces to the expected result:  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{P}(\\mathbf{k}) = \\sigma^2\\Delta\\nu\\Delta\\Omega X^2Y.\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "For the case of calculating $\\hat{P}(\\mathbf{k})$ with autocorrelations of time-offset visibilites, the quantity $\\Delta\\mathbf{b}_{ij}$ may be written as  \n",
    "  \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\Delta\\mathbf{b}_{ii}(t) = \\bigl(\\mathbf{I} - \\mathbf{R}(\\mathbf{\\omega}_\\oplus\\delta t)\\bigr)\\mathbf{b}_{i}(t),\n",
    "\\end{equation}\n",
    "$$\n",
    "  \n",
    "where $\\mathbf{I}$ is the identity matrix, $\\mathbf{R}(\\mathbf{\\omega}_\\oplus\\delta t)$ is a matrix that rotates $\\mathbf{b}_i$ about the Earth's rotational axis by a phase $\\omega_\\oplus{\\delta}t$, where $\\omega_\\oplus$ is the angular frequency of Earth's rotation and ${\\delta}t$ is the time-offset between visibilities. For our case, ${\\delta}t$ corresponds to the integration time-step used in the simulation. In order to determine the expected amplitude of the imaginary component of the power spectrum, we integrate equation$~\\ref{eq:pspec-expectation}$ numerically using a HEALPix map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
